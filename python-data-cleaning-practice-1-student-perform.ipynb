{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3700232,"sourceType":"datasetVersion","datasetId":2213802}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"****\n**Goal:**\nPractice real-world data cleaning and validation using Python and pandas—focusing on the steps an analyst or data engineer would take before loading data into a pipeline.\n\n**Dataset:** Student Performance Data\n\n(395 rows × 33 columns, secondary school student data)\n\n**Key Tasks:**\n\nLoad CSV file from /kaggle/input/\n\nInspect column structure, data types, and null values\n\nRemove duplicates and standardize column names\n\nValidate numeric ranges (age, grades, alcohol use)\n\nCreate automated checks and an “at-risk” flag\n\nSave cleaned and augmented datasets to /kaggle/working/\n\n**Outputs Generated:**\n\nFile\tPurpose\nstudent_performance_cleaned.csv\tMain cleaned dataset\nstudent_performance_cleaned_augmented.csv\tCleaned + engineered columns\nsummary_numeric.csv\tNumeric profile (stats summary)\nfrequencies.csv\tCategory frequencies\nflagged_at_risk_students.csv\tStudents flagged by ETL rules\nreport.txt\tQuick data-quality summary\n\n**Learning Notes:**\n\nPracticing df.info(), df.describe(), and isna().sum() builds data intuition.\n\nEven clean datasets can benefit from standardization and basic validation.\n\nWriting outputs to /working/ mimics staging/ETL data handoffs.\n\nAdding automation (like flags and reports) brings structure to analytics workflows.","metadata":{}},{"cell_type":"code","source":"# Import essential libraries \nimport pandas as pd\n\n# Load the dataset\nfile_path = '/kaggle/input/student-performance-data/student_data.csv'\ndf = pd.read_csv(file_path)\n\n#Inspect the first few rows\ndf.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-16T01:22:51.627191Z","iopub.execute_input":"2025-10-16T01:22:51.627473Z","iopub.status.idle":"2025-10-16T01:22:51.648324Z","shell.execute_reply.started":"2025-10-16T01:22:51.627450Z","shell.execute_reply":"2025-10-16T01:22:51.647350Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n\n  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n0      4        3      4     1     1      3        6   5   6   6  \n1      5        3      3     1     1      3        4   5   5   6  \n2      4        3      2     2     3      3       10   7   8  10  \n3      3        2      2     1     1      5        2  15  14  15  \n4      4        3      2     1     2      5        4   6  10  10  \n\n[5 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>school</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>address</th>\n      <th>famsize</th>\n      <th>Pstatus</th>\n      <th>Medu</th>\n      <th>Fedu</th>\n      <th>Mjob</th>\n      <th>Fjob</th>\n      <th>...</th>\n      <th>famrel</th>\n      <th>freetime</th>\n      <th>goout</th>\n      <th>Dalc</th>\n      <th>Walc</th>\n      <th>health</th>\n      <th>absences</th>\n      <th>G1</th>\n      <th>G2</th>\n      <th>G3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>18</td>\n      <td>U</td>\n      <td>GT3</td>\n      <td>A</td>\n      <td>4</td>\n      <td>4</td>\n      <td>at_home</td>\n      <td>teacher</td>\n      <td>...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>5</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>17</td>\n      <td>U</td>\n      <td>GT3</td>\n      <td>T</td>\n      <td>1</td>\n      <td>1</td>\n      <td>at_home</td>\n      <td>other</td>\n      <td>...</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>15</td>\n      <td>U</td>\n      <td>LE3</td>\n      <td>T</td>\n      <td>1</td>\n      <td>1</td>\n      <td>at_home</td>\n      <td>other</td>\n      <td>...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>10</td>\n      <td>7</td>\n      <td>8</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>15</td>\n      <td>U</td>\n      <td>GT3</td>\n      <td>T</td>\n      <td>4</td>\n      <td>2</td>\n      <td>health</td>\n      <td>services</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>15</td>\n      <td>14</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>16</td>\n      <td>U</td>\n      <td>GT3</td>\n      <td>T</td>\n      <td>3</td>\n      <td>3</td>\n      <td>other</td>\n      <td>other</td>\n      <td>...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>6</td>\n      <td>10</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Inspect data structure and quality \n\n# Basic information about columns, types and non-null counts\ndf.info()\n\n# Quick statistical summary (only for numeric columns)\ndf.describe()\n\n# Count of missing values per column \ndf.isna().sum()\n\n# Check for duplicate rows\ndf.duplicated().sum()\n\n# Display column names for reference\ndf.columns.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T23:31:37.467008Z","iopub.execute_input":"2025-10-15T23:31:37.467384Z","iopub.status.idle":"2025-10-15T23:31:37.523866Z","shell.execute_reply.started":"2025-10-15T23:31:37.467361Z","shell.execute_reply":"2025-10-15T23:31:37.522964Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 395 entries, 0 to 394\nData columns (total 33 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   school      395 non-null    object\n 1   sex         395 non-null    object\n 2   age         395 non-null    int64 \n 3   address     395 non-null    object\n 4   famsize     395 non-null    object\n 5   Pstatus     395 non-null    object\n 6   Medu        395 non-null    int64 \n 7   Fedu        395 non-null    int64 \n 8   Mjob        395 non-null    object\n 9   Fjob        395 non-null    object\n 10  reason      395 non-null    object\n 11  guardian    395 non-null    object\n 12  traveltime  395 non-null    int64 \n 13  studytime   395 non-null    int64 \n 14  failures    395 non-null    int64 \n 15  schoolsup   395 non-null    object\n 16  famsup      395 non-null    object\n 17  paid        395 non-null    object\n 18  activities  395 non-null    object\n 19  nursery     395 non-null    object\n 20  higher      395 non-null    object\n 21  internet    395 non-null    object\n 22  romantic    395 non-null    object\n 23  famrel      395 non-null    int64 \n 24  freetime    395 non-null    int64 \n 25  goout       395 non-null    int64 \n 26  Dalc        395 non-null    int64 \n 27  Walc        395 non-null    int64 \n 28  health      395 non-null    int64 \n 29  absences    395 non-null    int64 \n 30  G1          395 non-null    int64 \n 31  G2          395 non-null    int64 \n 32  G3          395 non-null    int64 \ndtypes: int64(16), object(17)\nmemory usage: 102.0+ KB\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['school',\n 'sex',\n 'age',\n 'address',\n 'famsize',\n 'Pstatus',\n 'Medu',\n 'Fedu',\n 'Mjob',\n 'Fjob',\n 'reason',\n 'guardian',\n 'traveltime',\n 'studytime',\n 'failures',\n 'schoolsup',\n 'famsup',\n 'paid',\n 'activities',\n 'nursery',\n 'higher',\n 'internet',\n 'romantic',\n 'famrel',\n 'freetime',\n 'goout',\n 'Dalc',\n 'Walc',\n 'health',\n 'absences',\n 'G1',\n 'G2',\n 'G3']"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Basic cleaning - duplicates and formatting\n\n# Check and remove duplicates\nduplicates = df.duplicated().sum()\nprint(f\"Duplicate rows found: {duplicates}\")\n\nif duplicates > 0:\n    df = df.drop_duplicates()\n    print(\"Duplicates removed.\")\nelse:\n    print(\"No duplicates found.\")\n\n# Standardize column name (optional but good practice)\ndf.columns = df.columns.str.strip().str.lower()\n\n# Verify column name changes\nprint(\"\\nUpdated column names:\\n\", df.columns.tolist())\n\n# Confirm shape after cleaning \nprint(f\"\\nDataset shape after cleaning: {df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T01:22:56.083752Z","iopub.execute_input":"2025-10-16T01:22:56.084147Z","iopub.status.idle":"2025-10-16T01:22:56.095386Z","shell.execute_reply.started":"2025-10-16T01:22:56.084078Z","shell.execute_reply":"2025-10-16T01:22:56.094679Z"}},"outputs":[{"name":"stdout","text":"Duplicate rows found: 0\nNo duplicates found.\n\nUpdated column names:\n ['school', 'sex', 'age', 'address', 'famsize', 'pstatus', 'medu', 'fedu', 'mjob', 'fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'dalc', 'walc', 'health', 'absences', 'g1', 'g2', 'g3']\n\nDataset shape after cleaning: (395, 33)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Data validation and sanity checks\n\n# Age should be between 10 and 22\ninvalid_ages = df[(df['age'] < 10) | (df['age'] > 22)]\nprint(\"Unusual ages:\\n\", invalid_ages['age'].unique())\n\n# Grades (g1, g2, g3) should be between 0 and 20\n\nfor col in ['g1', 'g2', 'g3']:\n    invalid = df[(df[col] < 0) | (df[col] > 20)]\n    if not invalid.empty:\n        print(f\"Unexpected values in {col}: {invalid[col].unique()}\")\n\n# Alcohol use score (dalc, walc) should be between 1 and 5\nfor col in ['dalc', 'walc']:\n    out_of_range = df[(df[col] < 1) | (df[col] > 5)]\n    if not out_of_range.empty:\n        print(f\"Out-of-range values in {col}: {out_of_range[col].unique()}\")\n\n# Quick look at category value counts for sanity \nprint(\"\\nUnique values in 'sex':\", df['sex'].unique())\nprint(\"\\nUnique values in 'school':\", df['school'].unique())\nprint(\"\\nUnique values in 'address':\", df['address'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T01:23:10.897514Z","iopub.execute_input":"2025-10-16T01:23:10.897834Z","iopub.status.idle":"2025-10-16T01:23:10.909562Z","shell.execute_reply.started":"2025-10-16T01:23:10.897809Z","shell.execute_reply":"2025-10-16T01:23:10.908523Z"}},"outputs":[{"name":"stdout","text":"Unusual ages:\n []\n\nUnique values in 'sex': ['F' 'M']\n\nUnique values in 'school': ['GP' 'MS']\n\nUnique values in 'address': ['U' 'R']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Save the cleaned dataset\n\noutput_path = '/kaggle/working/student_performance_cleaned.csv'\ndf.to_csv(output_path, index=False)\n\nprint(f\"Cleaned dataset saved to: {output_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T02:03:33.518893Z","iopub.execute_input":"2025-10-16T02:03:33.519238Z","iopub.status.idle":"2025-10-16T02:03:33.533857Z","shell.execute_reply.started":"2025-10-16T02:03:33.519211Z","shell.execute_reply":"2025-10-16T02:03:33.533153Z"}},"outputs":[{"name":"stdout","text":"Cleaned dataset saved to: /kaggle/working/student_performance_cleaned.csv\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Automation — quick summary + \"at_risk\" flag\n\nimport numpy as np\nimport pandas as pd # safe if already imported \n\n# Numeric summary (describe each numeric column)\nnumeric_cols = df.select_dtypes(include='number').columns\nsummary = df[numeric_cols].describe().T\nsummary_path = '/kaggle/working/summary_numeric.csv'\nsummary.to_csv(summary_path)\n\n# Category frequency tables for quick data checks\ncat_cols = ['sex', 'school', 'address', 'famsize', 'pstatus', 'mjob', 'fjob',\n            'schoolsup', 'famsup', 'internet']\nfreqs = {}\nfor c in cat_cols:\n    if c in df.columns:\n        freqs[c] = df[c].value_counts(dropna=False)\n\n# Save category frequencies to a single wide CSV\nfreq_df = pd.concat({k: v for k, v in freqs.items()}, axis=1)\nfreq_path = '/kaggle/working/frequencies.csv'\nfreq_df.to_csv(freq_path)\n\n# Simple rule-based \"at-risk\" flag (ETL-style feature engineering)\n#    - low final grade (g3 < 10)\n#    - steady decline across terms (g1 > g2 > g3) with a drop of 4+ points total\n#    - high absences (>= 10)\n#    - prior failures (> 0)\n#    - very high weekend alcohol use (walc >= 4)\ndf['grade_mean'] = df[['g1', 'g2', 'g3']].mean(axis=1)\ndf['grade_decline'] = (df['g1'] > df['g2']) & (df['g2'] > df['g3'])\ndf['high_absences'] = df['absences'] >= 10\ndf['prior_failures'] = df['failures'] > 0\ndf['high_weekend_alc'] = df['walc'] >= 4\n\ndf['at_risk'] = (\n    (df['g3'] < 10) |\n    (df['grade_decline'] & (df['g1'] - df['g3'] >= 4)) |\n    df['high_absences'] |\n    df['prior_failures'] |\n    df['high_weekend_alc']\n)\n\n# Save flagged subset and augmented cleaned dataset\nflagged = df[df['at_risk']].copy()\nflagged_path = '/kaggle/working/flagged_at_risk_students.csv'\nflagged.to_csv(flagged_path, index=False)\n\naugmented_path = '/kaggle/working/student_performance_cleaned_augmented.csv'\ndf.to_csv(augmented_path, index=False)\n\n# Tiny human-readable report (quick win for stakeholders)\nreport_lines = [\n    f\"Total rows: {len(df)}\",\n    f\"At-risk students: {flagged.shape[0]}\",\n    f\"Avg G3: {df['g3'].mean():.2f}\",\n    f\"Median absences: {df['absences'].median()}\",\n    f\"Share with prior failures: {df['prior_failures'].mean():.1%}\",\n]\nreport_path = '/kaggle/working/report.txt'\nwith open(report_path, 'w') as f:\n    f.write('\\n'.join(report_lines))\n\nprint(\"Saved:\")\nprint(\"-\", summary_path)\nprint(\"-\", freq_path)\nprint(\"-\", flagged_path)\nprint(\"-\", augmented_path)\nprint(\"-\", report_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T02:16:33.763718Z","iopub.execute_input":"2025-10-16T02:16:33.764019Z","iopub.status.idle":"2025-10-16T02:16:33.826656Z","shell.execute_reply.started":"2025-10-16T02:16:33.763994Z","shell.execute_reply":"2025-10-16T02:16:33.825985Z"}},"outputs":[{"name":"stdout","text":"Saved:\n- /kaggle/working/summary_numeric.csv\n- /kaggle/working/frequencies.csv\n- /kaggle/working/flagged_at_risk_students.csv\n- /kaggle/working/student_performance_cleaned_augmented.csv\n- /kaggle/working/report.txt\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"**Reflection:**\nThis project helped me slow down and really understand what’s happening behind each pandas command instead of just copying code. I got to practice how data engineers clean and validate datasets before they’re used for analysis. It was simple but rewarding to see the process from inspection all the way to saving clean, structured data and building a small automation that feels practical for real work.","metadata":{}}]}